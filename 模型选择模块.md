# 模型选择模块

## 2026年MCM问题C：与星共舞（Dancing with the Stars）模型选择方案

---

## 一、模型选择总览

本模块针对四个核心问题，分别推荐**基础适配方案（保分核心）**和**创新融合方案（冲奖关键）**两种模型策略，并给出最终采用方案。

| 问题 | 基础方案 | 创新方案 | **最终采用方案** |
|------|---------|---------|-----------------|
| 问题1：粉丝投票估算 | 约束线性规划+Bootstrap采样 | 贝叶斯推断+MCMC采样融合 | **双方案结合**（约束优化提供点估计 + 贝叶斯提供不确定性量化） |
| 问题2：方法对比分析 | 配对t检验+Wilcoxon秩和检验 | 随机森林+SHAP可解释分析 | **方案二**（随机森林+SHAP可解释分析） |
| 问题3：特征影响分析 | 多元线性回归+逐步回归特征筛选 | XGBoost+SHAP值特征重要性分析 | **双方案结合**（回归提供系数解释 + XGBoost提供重要性排序） |
| 问题4：新系统设计 | 多目标线性规划+帕累托优化 | 强化学习+动态权重调整机制 | **方案二**（强化学习+动态权重调整机制） |

---

## 二、问题1：粉丝投票估算模型

### 2.1 方案1：约束线性规划+Bootstrap采样（基础适配方案）

#### 2.1.1 核心原理

约束线性规划模型通过建立评委评分与粉丝投票之间的线性映射关系，在满足排名/淘汰约束条件下，反推最可能的粉丝投票数分布。具体而言：

- **数学建模思路**：设第$i$位选手第$w$周的粉丝投票数为$V_{i,w}$，评委总分为$J_{i,w}$。根据题目规则，粉丝投票百分比$P_{fan}^{(i)}$与评委评分百分比$P_{judge}^{(i)}$按某种权重合并计算总分，决定淘汰顺序。我们将这一过程建模为：
  $$\min \sum_{i,w} (V_{i,w} - \hat{V}_{i,w})^2$$
  约束条件包括：排名约束（淘汰者的总分最低）、非负约束（$V_{i,w} \geq 0$）、百分比归一化约束（$\sum_i P_{fan}^{(i)} = 1$）。

- **Bootstrap采样增强**：由于粉丝投票存在多解性，采用Bootstrap重采样方法（1000次采样），对每次采样数据求解优化问题，最终统计粉丝投票估算值的均值和置信区间，量化估算的确定性。

#### 2.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **数据字段匹配** | 核心输入为`week*_judge*_score`（连续数值），目标输出为粉丝投票估算值，完美匹配线性规划模型的输入输出结构 |
| **规则约束体现** | 可灵活处理三个时期（排名法/百分比法/评委决定法）的不同规则，通过调整约束条件实现规则切换 |
| **单/多维度覆盖** | 单维度：逐周求解；多维度：跨周联合优化，考虑选手累积表现趋势 |
| **缺失值处理** | 对N/A值（第4评委缺席）和0值（已淘汰选手）通过约束条件自然处理 |

#### 2.1.3 创新点（美赛适配改进）

1. **分阶段约束建模**：根据赛季1-2（排名法）、3-27（百分比法）、28-34（排名法+评委决定）三个时期，设计差异化约束函数，精确还原规则变化
2. **Bootstrap确定性度量**：引入Bootstrap采样量化估算不确定性，输出置信区间而非单一点估计，增强结论可信度
3. **松弛变量引入**：在硬约束基础上引入松弛变量，允许模型在边界情况下有限度偏离，提升模型鲁棒性

#### 2.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **多解问题** | 粉丝投票数存在无穷多可行解 | 添加正则化项（如最小化投票数方差），引导解向合理区间收敛 |
| **线性假设局限** | 实际投票行为可能非线性 | 引入分段线性或二次项扩展模型 |
| **对异常值敏感** | 争议案例（如Bobby Bones）可能导致优化失败 | 采用鲁棒优化方法，对异常周数据降权处理 |
| **计算复杂度** | Bootstrap需多次求解优化问题 | 采用warm-start策略，复用上一次解作为初始点 |

---

### 2.2 方案2：贝叶斯推断+MCMC采样融合（创新融合方案）

#### 2.2.1 核心原理

贝叶斯推断模型将粉丝投票数视为待估计的隐变量，通过建立生成模型描述"粉丝投票→合并计算→淘汰结果"的正向过程，利用马尔可夫链蒙特卡洛（MCMC）方法从后验分布中采样，获得粉丝投票数的概率分布估计。

- **生成模型构建**：
  - 先验分布：假设粉丝投票数服从某种分布（如正态分布或Dirichlet分布），反映对投票行为的先验认知
  - 似然函数：给定粉丝投票和评委评分，计算观察到实际淘汰结果的概率
  - 后验分布：通过贝叶斯公式，结合先验和似然更新对粉丝投票的估计

- **MCMC采样**：采用Gibbs采样或Metropolis-Hastings算法，从高维后验分布中采样，生成大量粉丝投票数的样本，统计其分布特征（均值、方差、分位数）。

#### 2.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **数据字段匹配** | 核心数据为评委评分（连续型）和淘汰结果（离散型），贝叶斯模型天然支持混合类型数据建模 |
| **不确定性量化** | 直接输出后验分布，自然给出置信区间和确定性度量，完美契合题目对"确定性"的要求 |
| **规则嵌入** | 通过似然函数设计灵活嵌入不同时期的合并规则 |
| **层次建模** | 可构建层次贝叶斯模型，区分赛季级别、选手级别、周级别的投票模式差异 |

#### 2.2.3 创新点（美赛高奖关键）

1. **概率化建模范式**：区别于传统的点估计方法，贝叶斯方法输出完整的概率分布，体现对数据不确定性的深刻理解
2. **层次贝叶斯结构**：构建赛季→选手→周的层次结构，捕捉不同层级的投票模式差异
3. **信息先验融合**：将行业知识（如热门行业选手可能获得更多投票）融入先验分布，增强模型的解释性和预测精度
4. **收敛诊断可视化**：通过MCMC收敛诊断（Gelman-Rubin统计量、迹图）展示估计过程的可靠性

#### 2.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **计算成本高** | MCMC采样需大量迭代 | 采用高效采样算法（如NUTS），或使用变分推断作为替代 |
| **先验敏感性** | 不当的先验设置影响后验结果 | 进行先验敏感性分析，比较不同先验下的结果一致性 |
| **模型复杂度** | 层次模型参数众多 | 采用模型比较准则（WAIC/LOO-CV）选择最优模型复杂度 |
| **收敛困难** | 高维空间采样可能不收敛 | 增加采样链数量，延长burn-in期，使用自适应采样策略 |

---

### 2.3 问题1可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题1：粉丝投票估算模型流程图                              │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：评委评分矩阵 (421选手 × 11周 × 4评委)                                   │
│ 输出：数据抽象模型 → 选手-周-评分三维张量                                      │
│ 决策：是否按赛季规则分组？→ 是：分为三组（1-2季/3-27季/28-34季）               │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：缺失值处理                                                          │
│   - N/A值（第4评委缺席）→ 标记为缺失，计算时排除                              │
│   - 0值（已淘汰选手）→ 标记为非参与状态                                       │
│ 步骤2.2：评分归一化                                                          │
│   - 计算各周各选手的评委总分                                                  │
│   - 转换为百分比/排名形式                                                    │
│ 输出：预处理后的评分矩阵 + 淘汰标签向量                                       │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：评分特征提取                                                        │
│   - 周评委总分、累积评分、评分趋势（上升/下降）                               │
│ 步骤3.2：赛季规则编码                                                        │
│   - 排名法标记（赛季1-2, 28-34）                                             │
│   - 百分比法标记（赛季3-27）                                                 │
│ 输出：特征矩阵 X (n×d维)                                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：约束优化  │       │ 方案2：贝叶斯推断│                   │
│ ├─目标函数设计   │       │ ├─先验分布设定   │                   │
│ ├─约束条件构建   │       │ ├─似然函数构建   │                   │
│ └─求解器选择     │       │ └─MCMC采样配置   │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：模型求解/采样                                                       │
│   - 约束优化：使用CVXPY/Scipy求解器                                          │
│   - 贝叶斯推断：运行MCMC采样（10000次迭代，burn-in=2000）                     │
│ 步骤5.2：收敛检验                                                            │
│   - 决策：模型是否收敛？                                                     │
│     → 否：调整参数（正则化系数/先验超参数），返回步骤5.1                       │
│     → 是：进入结果验证                                                       │
│ 输出：粉丝投票估算值 + 采样分布                                              │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：一致性检验                                                          │
│   - 模型预测淘汰结果 vs 实际淘汰结果                                          │
│   - 计算准确率、Kappa系数、混淆矩阵                                           │
│ 步骤6.2：确定性评估                                                          │
│   - 计算95%置信区间                                                          │
│   - 评估逐选手/逐周的确定性差异                                              │
│ 决策：一致性是否达标（>80%）？                                               │
│   → 否：回溯调整模型结构，返回阶段4                                           │
│   → 是：输出最终结果                                                         │
│ 输出：一致性指标图 + 置信区间图 + 确定性分层报告                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 2.4 最终采用方案：双方案结合

#### 2.4.1 方案结合策略

问题1采用**约束线性规划+贝叶斯推断双方案结合**策略，充分发挥两种方法的互补优势：

| 方法组件 | 核心作用 | 输出贡献 |
|----------|---------|---------|
| 约束线性规划 | 提供粉丝投票的**点估计值** | 用于后续问题2、3的分析输入 |
| Bootstrap采样 | 提供估算的**确定性度量** | 回答子问题1.2"确定性有多高" |
| 贝叶斯推断 | 提供粉丝投票的**后验分布** | 刻画不确定性的完整形态 |
| MCMC采样 | 提供**分层确定性分析** | 回答子问题1.3"各选手/周确定性差异" |

#### 2.4.2 Placement约束条件详解

在模型构建中，**placement（最终排名）**作为关键约束条件，确保粉丝投票估算与比赛实际结果一致：

**约束1：淘汰排名约束**
$$\text{Total\_Score}_{eliminated} < \text{Total\_Score}_{survivor}, \quad \forall \text{周次}$$
- 每周被淘汰选手的合并总分必须严格低于所有晋级选手
- 使用placement字段中的"Eliminated Week X"信息构建约束

**约束2：最终排名序约束**
$$\text{placement}_i < \text{placement}_j \Rightarrow \text{Cumulative\_Score}_i > \text{Cumulative\_Score}_j$$
- 最终排名（placement=1,2,3...）与累积得分保持单调关系
- 冠军(placement=1)的累积表现应优于亚军(placement=2)

**约束3：决赛阶段特殊约束**（赛季28-34）
$$\text{Bottom2\_Score}_{saved} > \text{Bottom2\_Score}_{eliminated}$$
- 排名垫底的两位选手中，评委投票保留者的评委评分更高
- 体现"评委决定淘汰"规则

**约束4：非负与归一化约束**
$$V_{i,w} \geq 0, \quad \sum_i P_{fan}^{(i)} = 1$$
- 粉丝投票数非负
- 粉丝投票百分比归一化

#### 2.4.3 结合流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    双方案结合执行流程                                         │
└─────────────────────────────────────────────────────────────────────────────┘

步骤1：约束线性规划求解
    │
    ├─ 构建placement约束条件（淘汰序、排名序、决赛规则）
    ├─ 求解最优粉丝投票点估计
    └─ 输出：V_hat（点估计值）
    │
    ▼
步骤2：Bootstrap确定性评估
    │
    ├─ 对评委评分数据进行1000次重采样
    ├─ 每次重采样求解约束优化问题
    └─ 输出：95%置信区间、标准误差
    │
    ▼
步骤3：贝叶斯推断后验分析
    │
    ├─ 以约束优化结果作为先验中心
    ├─ 构建似然函数（基于placement约束）
    ├─ MCMC采样获取后验分布
    └─ 输出：后验均值、后验方差、分位数
    │
    ▼
步骤4：结果整合与验证
    │
    ├─ 对比两种方法的估算一致性
    ├─ 分层分析各选手/周的确定性差异
    └─ 输出：综合估算报告 + 确定性分层图
```

#### 2.4.4 预期输出

| 输出项 | 来源方法 | 用途 |
|--------|---------|------|
| 粉丝投票点估计表 | 约束线性规划 | 问题2、3的输入数据 |
| 估算置信区间 | Bootstrap | 回答子问题1.2 |
| 后验分布图 | 贝叶斯+MCMC | 论文可视化 |
| 分层确定性报告 | 双方法对比 | 回答子问题1.3 |
| 一致性指标 | 模型验证 | 回答子问题1.1 |

---

## 三、问题2：投票合并方法对比分析

### 3.1 方案1：配对t检验+Wilcoxon秩和检验（基础适配方案）

#### 3.1.1 核心原理

配对检验方法通过统计假设检验框架，量化分析排名法和百分比法产生结果的显著性差异。

- **配对t检验**：针对两种方法下同一选手的最终排名/得分，计算配对差异的均值是否显著异于零
  $$t = \frac{\bar{d}}{s_d/\sqrt{n}}$$
  其中$\bar{d}$为配对差异均值，$s_d$为标准差，$n$为样本量。

- **Wilcoxon秩和检验**：作为非参数替代方案，不依赖正态分布假设，对排名数据更为适用。通过比较两种方法产生的排名分布差异，计算W统计量和p值。

- **效应量计算**：采用Cohen's d或秩双列相关系数量化差异的实际意义大小，避免仅依赖p值判断。

#### 3.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **数据类型匹配** | 排名数据为有序离散型，Wilcoxon检验专为此类数据设计 |
| **配对设计** | 同一选手在两种规则下的表现构成天然配对，减少个体差异干扰 |
| **假设检验框架** | 输出p值和置信区间，符合学术论文规范 |
| **争议案例分析** | 可针对特定选手计算其在两种方法下的差异Z-score |

#### 3.1.3 创新点（美赛适配改进）

1. **分层配对检验**：按赛季、周数、选手行业分层进行配对检验，识别差异的主要来源
2. **多重检验校正**：采用Bonferroni或FDR方法校正多重比较问题，控制假阳性率
3. **效应量可视化**：绘制效应量森林图，直观展示不同维度的差异大小

#### 3.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **正态假设敏感** | t检验依赖正态分布假设 | 优先使用Wilcoxon非参数检验 |
| **仅能检测差异** | 无法解释差异来源 | 结合回归分析探索影响因素 |
| **对极端值敏感** | 争议案例可能主导检验结果 | 进行稳健性分析（剔除极端值后重测） |

---

### 3.2 方案2：随机森林+SHAP可解释分析（创新融合方案）

#### 3.2.1 核心原理

随机森林分类器结合SHAP（SHapley Additive exPlanations）可解释性分析，不仅能预测两种方法产生的结果差异，还能深入揭示导致差异的关键因素。

- **随机森林建模**：以"两种方法是否产生不同淘汰结果"为目标变量（二分类），特征包括评委评分、选手特征、赛季周数等，训练随机森林分类器。

- **SHAP值分析**：利用博弈论中的Shapley值原理，计算每个特征对预测结果的边际贡献，生成全局和局部的可解释性报告：
  - 全局重要性：哪些因素最能解释两种方法的差异
  - 局部解释：争议案例（如Bobby Bones）中各因素的具体贡献

#### 3.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **特征多样性** | 可同时处理连续（评分）、离散（行业）、有序（排名）等多种特征类型 |
| **非线性捕捉** | 随机森林可捕捉评分与差异之间的非线性关系 |
| **可解释性** | SHAP提供直观的特征贡献可视化，满足论文图表需求 |
| **争议案例分析** | 可针对单个案例生成局部解释，精准分析争议来源 |

#### 3.2.3 创新点（美赛高奖关键）

1. **因果推断视角**：结合反事实分析（Counterfactual）探索"如果采用另一种方法，该选手排名会如何变化"
2. **交互效应挖掘**：通过SHAP交互图发现特征间的协同效应（如高评分+热门行业的组合效应）
3. **偏向性量化**：定义偏向粉丝/评委的SHAP-based指数，量化两种方法的系统性偏差
4. **动态可视化**：制作SHAP瀑布图、蜂群图等高质量可视化，提升论文图表档次

#### 3.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **样本量要求** | 随机森林需要足够样本量 | 采用重采样或数据增强技术 |
| **过拟合风险** | 特征过多可能导致过拟合 | 使用交叉验证和特征选择 |
| **SHAP计算成本** | 精确SHAP值计算复杂度高 | 采用TreeSHAP等近似算法 |
| **因果解释限制** | SHAP反映相关性而非因果性 | 论文中明确区分相关性与因果性解释 |

---

### 3.3 问题2可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题2：投票合并方法对比分析流程图                          │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：问题1的粉丝投票估算结果 + 评委评分数据                                  │
│ 输出：两种方法的对比数据框架                                                 │
│   - 排名法计算引擎：基于排名合并计算总分                                      │
│   - 百分比法计算引擎：基于百分比合并计算总分                                  │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：方法结果计算                                                        │
│   - 对全部选手×周，分别用两种方法计算合并得分                                 │
│ 步骤2.2：差异标记                                                            │
│   - 标记两种方法产生不同淘汰结果的周次                                        │
│   - 提取4个争议案例数据                                                      │
│ 输出：对比数据矩阵 + 争议案例子集                                            │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：差异特征构建                                                        │
│   - 排名差异 = 排名法排名 - 百分比法排名                                     │
│   - 得分差异 = 排名法得分 - 百分比法得分                                     │
│ 步骤3.2：上下文特征                                                          │
│   - 选手当周评委排名、累积评分、行业类别                                     │
│ 输出：特征矩阵（含差异特征和上下文特征）                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：配对检验  │       │ 方案2：RF+SHAP  │                   │
│ ├─配对t检验     │       │ ├─随机森林训练  │                   │
│ ├─Wilcoxon检验  │       │ ├─SHAP值计算    │                   │
│ └─效应量计算    │       │ └─交互效应分析  │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：统计检验执行                                                        │
│   - 计算t统计量、W统计量、p值                                                │
│   - 应用多重检验校正                                                         │
│ 步骤5.2：机器学习训练                                                        │
│   - 5折交叉验证训练随机森林                                                  │
│   - 决策：模型是否过拟合（训练-测试AUC差距>0.1）？                            │
│     → 是：增加正则化（减少树深度/增加min_samples）                           │
│     → 否：计算SHAP值                                                        │
│ 输出：检验统计量 + 随机森林模型 + SHAP值矩阵                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：差异显著性报告                                                      │
│   - 生成p值汇总表、效应量森林图                                              │
│ 步骤6.2：争议案例深度分析                                                    │
│   - 4个争议案例的SHAP瀑布图                                                  │
│   - 反事实模拟："如果用另一种方法会怎样"                                     │
│ 步骤6.3：方法推荐论证                                                        │
│   - 基于分析结果给出方法推荐及理由                                           │
│ 输出：对比分析报告 + 争议案例图表 + 方法推荐书                               │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 3.4 最终采用方案：随机森林+SHAP可解释分析（方案二）

#### 3.4.1 采用理由

问题2最终采用**方案二：随机森林+SHAP可解释分析**，主要基于以下考量：

| 决策因素 | 方案一局限 | 方案二优势 |
|----------|-----------|-----------|
| **差异解释能力** | 配对检验仅能检测差异存在，无法解释差异来源 | SHAP可精确分解每个特征对差异的贡献 |
| **争议案例分析** | 只能给出整体统计量，无法针对单个案例 | 局部SHAP解释可深度剖析Bobby Bones等争议案例 |
| **特征交互发现** | 无法捕捉特征间交互效应 | 随机森林+SHAP交互图可发现组合效应 |
| **可视化丰富度** | 输出较单一（p值、效应量） | SHAP瀑布图、蜂群图等满足美赛图表要求 |
| **美赛创新性** | 传统统计方法创新点有限 | 可解释AI为C题高分亮点 |

#### 3.4.2 核心执行策略

**目标变量定义**：
$$Y = \begin{cases} 1, & \text{两种方法产生不同淘汰结果} \\ 0, & \text{两种方法产生相同淘汰结果} \end{cases}$$

**特征工程**：
| 特征类别 | 具体特征 | 数据来源 |
|----------|---------|---------|
| 评分特征 | 当周评委总分、评委排名、评分变化趋势 | 官方数据 |
| 投票特征 | 问题1估算的粉丝投票百分比 | 模型输出 |
| 选手特征 | 行业、年龄、地域 | 官方数据 |
| 时序特征 | 赛季、周次、剩余选手数 | 官方数据 |

**SHAP分析输出**：
1. **全局特征重要性**：识别影响两种方法差异的关键因素
2. **SHAP依赖图**：揭示评委评分与差异概率的非线性关系
3. **争议案例瀑布图**：逐特征分解4个争议案例的差异来源
4. **偏向性SHAP指数**：量化两种方法对评委/粉丝的系统性偏向

#### 3.4.3 争议案例深度分析框架

针对题目指定的4个争议案例，采用SHAP局部解释：

| 案例 | 赛季 | 分析重点 | SHAP输出 |
|------|------|---------|---------|
| Jerry Rice | S2 | 5周评委最低仍获亚军 | 粉丝投票特征贡献度 |
| Billy Ray Cyrus | S4 | 5周评委最低分 | 行业特征（乡村音乐）贡献度 |
| Bristol Palin | S11 | 12次评委最低，排名第三 | 政治背景特征贡献度 |
| Bobby Bones | S27 | 评委低分却获胜 | 社交影响力特征贡献度 |

#### 3.4.4 预期输出

| 输出项 | 描述 | 论文用途 |
|--------|------|---------|
| 特征重要性条形图 | 影响方法差异的Top 10特征 | Figure X |
| SHAP蜂群图 | 全部特征的分布与影响方向 | Figure X+1 |
| 争议案例瀑布图×4 | 单案例的特征贡献分解 | Figure X+2~5 |
| 偏向性分析表 | 两种方法的系统性偏差量化 | Table X |
| 方法推荐论证 | 基于SHAP分析的方法选择建议 | 正文论述 |

---

## 四、问题3：名人特征影响分析

### 4.1 方案1：多元线性回归+逐步回归特征筛选（基础适配方案）

#### 4.1.1 核心原理

多元线性回归模型建立名人特征（年龄、行业、地域等）与比赛结果（评委评分/粉丝投票/最终排名）之间的线性关系：
$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p + \epsilon$$

- **逐步回归特征筛选**：采用前向选择（Forward Selection）或后向消除（Backward Elimination）策略，基于AIC/BIC准则自动选择最优特征子集，避免多重共线性问题。

- **分层回归分析**：分别建立对评委评分和粉丝投票的回归模型，比较同一特征在两个模型中的系数差异，揭示特征对评委vs粉丝的差异化影响。

#### 4.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **特征类型处理** | 类别特征（行业、州）通过哑变量编码转换为数值型 |
| **系数可解释性** | 回归系数直接反映特征的边际影响，易于论文阐述 |
| **显著性检验** | 每个特征的t检验p值支持假设检验结论 |
| **差异化分析** | 通过对比两个回归模型的系数差异，实现对评委vs粉丝的差异化影响分析 |

#### 4.1.3 创新点（美赛适配改进）

1. **交互项建模**：引入年龄×行业、行业×地域等交互项，捕捉特征间的协同效应
2. **稳健标准误**：采用异方差稳健标准误（HC3），增强统计推断的稳健性
3. **分层对比设计**：构建评委评分模型和粉丝投票模型的系数对比表，直观展示差异化影响

#### 4.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **线性假设** | 特征与结果可能非线性相关 | 引入多项式项或分箱处理 |
| **多重共线性** | 类别特征编码后可能高度相关 | 采用VIF检验，删除高共线性变量 |
| **高维稀疏** | 类别特征编码后维度爆炸 | 采用正则化回归（Ridge/LASSO） |
| **缺失值敏感** | 补充数据存在大量缺失 | 仅将补充数据作为辅助验证 |

---

### 4.2 方案2：XGBoost+SHAP值特征重要性分析（创新融合方案）

#### 4.2.1 核心原理

XGBoost（eXtreme Gradient Boosting）是一种高效的梯度提升树集成算法，结合SHAP值分析，可实现高精度预测与深度可解释性的完美结合。

- **XGBoost建模**：以最终排名或投票比例为目标变量，名人特征为输入，训练XGBoost模型。通过梯度提升策略，逐步构建多棵决策树，每棵树学习前序模型的残差。

- **SHAP值特征重要性**：
  - **全局重要性**：计算各特征的平均绝对SHAP值，得到全局特征重要性排序
  - **局部解释**：对单个选手的预测结果，分解各特征的贡献
  - **依赖图**：展示特征值与SHAP值的关系，揭示非线性效应

#### 4.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **特征类型** | 天然支持数值和类别特征，无需复杂编码 |
| **非线性建模** | 决策树集成可捕捉复杂的非线性关系 |
| **缺失值处理** | XGBoost内置缺失值处理机制，自动学习最优分裂方向 |
| **特征交互** | 自动学习特征间的交互效应，无需手动构建交互项 |

#### 4.2.3 创新点（美赛高奖关键）

1. **SHAP依赖图创新应用**：绘制年龄-SHAP值依赖图，揭示"最佳参赛年龄区间"
2. **特征交互SHAP分析**：计算特征对的交互SHAP值，发现如"体育行业×年轻选手"的正向协同效应
3. **时序演化分析**：按赛季分组训练模型，分析特征重要性的时序演化趋势
4. **对评委vs粉丝的分层SHAP**：分别建立评委评分预测模型和粉丝投票预测模型，对比同一特征在两个模型中的SHAP值差异

#### 4.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **过拟合风险** | 树模型容易过拟合 | 采用早停法、L1/L2正则化、限制树深度 |
| **超参数敏感** | 性能依赖超参数设置 | 使用Optuna/GridSearch进行超参数调优 |
| **因果推断限制** | SHAP反映相关性 | 结合领域知识解读，明确声明相关性而非因果性 |
| **补充数据局限** | 社交粉丝数据覆盖率低 | 作为辅助特征使用，主模型基于核心数据 |

---

### 4.3 问题3可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题3：名人特征影响分析流程图                              │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：名人特征数据 + 问题1粉丝投票估算 + 评委评分                             │
│ 目标变量：                                                                   │
│   - Y1：评委总评分（反映评委偏好）                                            │
│   - Y2：粉丝投票估算值（反映粉丝偏好）                                        │
│   - Y3：最终排名（综合表现）                                                  │
│ 输出：多目标特征影响分析框架                                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：核心数据处理                                                        │
│   - 年龄：保留原始数值，检验分布形态                                          │
│   - 行业：哑变量编码或目标编码                                               │
│   - 地域：按人口/地域分组降维                                                │
│ 步骤2.2：补充数据处理（辅助）                                                │
│   - 社交粉丝数：对数变换，处理长尾分布                                        │
│   - 缺失值：标记为单独类别或使用多重插补                                      │
│ 输出：清洗后的特征数据框                                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：基础特征构建                                                        │
│   - 年龄分箱：青年(<30)/中年(30-45)/成熟(>45)                                │
│   - 行业分组：娱乐/体育/政治/其他                                            │
│   - 地域分组：东部/西部/南部/北部/非美国                                      │
│ 步骤3.2：交互特征构建                                                        │
│   - 年龄×行业、行业×地域                                                     │
│ 步骤3.3：舞者特征提取                                                        │
│   - 舞者历史胜率、舞者参赛次数                                               │
│ 输出：完整特征矩阵 (n×p维)                                                   │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：线性回归  │       │ 方案2：XGBoost  │                   │
│ ├─逐步回归       │       │ ├─超参数设置    │                   │
│ ├─VIF检验        │       │ ├─交叉验证配置  │                   │
│ └─稳健标准误     │       │ └─SHAP配置      │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：模型训练                                                            │
│   - 线性回归：OLS估计，逐步选择最优变量                                       │
│   - XGBoost：5折CV，早停法防过拟合                                           │
│ 步骤5.2：模型诊断                                                            │
│   - 决策：是否存在多重共线性（VIF>10）？                                      │
│     → 是：剔除高共线变量或采用Ridge回归                                       │
│   - 决策：XGBoost是否过拟合？                                                │
│     → 是：增加正则化参数，减少迭代次数                                        │
│ 输出：回归系数表 + XGBoost模型 + 训练曲线                                    │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：特征重要性输出                                                      │
│   - 回归系数显著性表（含p值、置信区间）                                       │
│   - SHAP全局重要性条形图                                                     │
│   - SHAP依赖图（年龄、行业等核心特征）                                        │
│ 步骤6.2：差异化影响对比                                                      │
│   - 评委模型 vs 粉丝模型 的特征重要性对比图                                   │
│   - 发现差异化特征（如某行业对粉丝吸引力强但评委不认可）                       │
│ 步骤6.3：交叉验证稳定性                                                      │
│   - 5折CV下的特征重要性一致性检验                                            │
│ 输出：特征重要性排序表 + 热力图 + 差异化分析报告                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 4.4 最终采用方案：双方案结合

#### 4.4.1 方案结合策略

问题3采用**多元线性回归+XGBoost双方案结合**策略，充分发挥统计模型的解释性和机器学习模型的预测能力：

| 方法组件 | 核心作用 | 输出贡献 |
|----------|---------|---------|
| 多元线性回归 | 提供特征的**回归系数和显著性检验** | 明确因果方向、支持假设检验论述 |
| 逐步回归 | 提供**最优特征子集** | 识别核心影响因素 |
| XGBoost | 提供**非线性特征重要性排序** | 捕捉复杂交互效应 |
| SHAP分析 | 提供**特征贡献的可视化解释** | 高质量论文图表 |

#### 4.4.2 名人特征定义与分类

**⚠️ 核心区分：名人特征 vs 舞者特征 vs 比赛特征**

根据题目要求，本问题聚焦于**名人特征（Celebrity Features）**对比赛结果的影响。以下是特征分类明细：

| 特征类别 | 数据字段 | 字段含义 | 是否为名人特征 |
|----------|---------|---------|---------------|
| **名人特征** | `celebrity_age_during_season` | 参赛时年龄 | ✓ 是 |
| **名人特征** | `celebrity_industry` | 名人所属行业 | ✓ 是 |
| **名人特征** | `celebrity_homestate` | 名人家乡州 | ✓ 是 |
| **名人特征** | `celebrity_homecountry/region` | 名人家乡国家/地区 | ✓ 是 |
| 补充特征 | `celebrity_total_followers_wikidata` | 名人社交媒体粉丝数 | ✓ 是（辅助） |
| 舞者特征 | `ballroom_partner` | 专业舞伴 | ✗ 否 |
| 舞者特征 | `partner_total_followers_wikidata` | 舞伴社交粉丝数 | ✗ 否 |
| 比赛特征 | `season` | 赛季号 | ✗ 否 |
| 比赛特征 | `week*_judge*_score` | 评委评分 | ✗ 否 |
| 结果特征 | `placement` | 最终排名 | ✗ 否（目标变量） |

**名人特征详细说明**：

| 名人特征 | 数据类型 | 处理方式 | 分析目标 |
|----------|---------|---------|---------|
| **参赛年龄** | 连续数值 | 保留原值+分箱（青年/中年/成熟） | 分析最佳参赛年龄区间 |
| **所属行业** | 类别变量 | 哑变量编码/目标编码 | 识别优势行业（体育/娱乐/政治等） |
| **家乡州** | 类别变量 | 地域分组（东/西/南/北部） | 分析地域人气差异 |
| **家乡国家** | 类别变量 | 二值化（美国/非美国） | 分析国籍影响 |
| **社交粉丝数** | 连续数值（辅助） | 对数变换 | 验证社交影响力假说 |

#### 4.4.3 双方案执行流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    名人特征影响分析：双方案结合流程                           │
└─────────────────────────────────────────────────────────────────────────────┘

步骤1：名人特征预处理
    │
    ├─ 年龄：检验分布，分箱处理
    ├─ 行业：识别主要类别，合并小类别
    ├─ 地域：按美国人口普查区域分组
    └─ 社交粉丝数（辅助）：对数变换，处理缺失值
    │
    ▼
步骤2：多元线性回归分析
    │
    ├─ 构建回归模型：Y（评分/投票/排名）~ 名人特征
    ├─ 逐步回归筛选显著变量（p<0.05）
    ├─ VIF检验多重共线性
    └─ 输出：回归系数表 + 显著性检验结果
    │
    ▼
步骤3：XGBoost+SHAP分析
    │
    ├─ 仅使用名人特征作为输入变量
    ├─ 5折交叉验证训练XGBoost
    ├─ 计算SHAP值
    └─ 输出：特征重要性排序 + SHAP依赖图
    │
    ▼
步骤4：双模型结果对比验证
    │
    ├─ 对比回归系数方向与SHAP值符号
    ├─ 验证重要性排序一致性
    └─ 输出：综合特征影响报告
    │
    ▼
步骤5：差异化影响分析
    │
    ├─ 分别建立评委评分模型和粉丝投票模型
    ├─ 对比同一名人特征在两个模型中的影响差异
    └─ 输出：评委vs粉丝差异化影响矩阵
```

#### 4.4.4 关键分析输出

| 分析任务 | 使用方法 | 输出形式 |
|----------|---------|---------|
| 名人特征显著性检验 | 多元线性回归 | 回归系数表（含p值、置信区间） |
| 名人特征重要性排序 | XGBoost+SHAP | 全局重要性条形图 |
| 年龄影响非线性分析 | SHAP依赖图 | 年龄-SHAP值曲线图 |
| 行业优势分析 | 回归系数+SHAP | 行业分组箱线图 |
| 地域影响分析 | 回归系数+SHAP | 地域热力图 |
| 评委vs粉丝差异化影响 | 双模型对比 | 特征影响对比表 |

#### 4.4.5 预期研究结论框架

基于双方案分析，预期得出以下类型的结论：

1. **年龄效应**："30-40岁选手在评委评分和粉丝投票中均表现最优"
2. **行业效应**："体育明星获得更高评委评分，娱乐明星获得更多粉丝投票"
3. **地域效应**："来自人口大州（加州、德州）的选手粉丝投票优势明显"
4. **差异化影响**："某些行业对评委和粉丝的影响方向相反"

---

## 五、问题4：新投票系统设计

### 5.1 方案1：多目标线性规划+帕累托优化（基础适配方案）

#### 5.1.1 核心原理

多目标优化模型同时考虑公平性、评委专业性保护、粉丝参与度等多个目标，设计最优的投票合并权重方案。

- **目标函数设计**：
  - 目标1（公平性）：最小化低评分选手晋级概率
  - 目标2（专业性）：最大化评委评分权重
  - 目标3（参与度）：最大化粉丝投票影响力

- **帕累托优化**：由于目标间存在冲突，采用帕累托前沿分析，找到所有非劣解（Pareto Optimal Solutions），提供多个方案供决策者选择。

- **约束条件**：权重非负、权重和为1、规则可操作性约束等。

#### 5.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **多目标平衡** | 帕累托优化天然适合多目标冲突场景 |
| **可解释性** | 每个帕累托解对应明确的权重配置 |
| **回测验证** | 可用历史数据验证各方案效果 |
| **灵活性** | 可根据节目需求调整目标权重 |

#### 5.1.3 创新点（美赛适配改进）

1. **公平性指标创新定义**：基于问题2和问题3的分析结果，定义"技能-结果一致性指数"作为公平性度量
2. **动态权重机制**：设计随比赛进程调整的动态权重（如决赛周增加评委权重）
3. **多情景分析**：生成多个帕累托方案，对比分析各方案的优劣势

#### 5.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **目标量化困难** | 公平性等抽象概念难以量化 | 基于问题1-3的分析结果构建代理指标 |
| **帕累托解过多** | 可能产生大量非劣解 | 采用聚类方法筛选代表性方案 |
| **线性假设** | 实际投票行为可能非线性 | 引入分段线性或非线性目标函数 |

---

### 5.2 方案2：强化学习+动态权重调整机制（创新融合方案）

#### 5.2.1 核心原理

强化学习（Reinforcement Learning）框架将投票系统设计建模为序贯决策问题，通过模拟比赛过程学习最优的动态权重调整策略。

- **状态空间**：当前周次、剩余选手数量、评委评分分布、历史投票趋势等
- **动作空间**：评委-粉丝投票的权重配置（如评委60%-粉丝40%）
- **奖励函数**：综合公平性、观赏性、粉丝满意度等指标

- **策略学习**：使用Q-Learning或Policy Gradient方法，学习状态到最优动作的映射，实现权重的动态调整。

#### 5.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **动态决策** | RL天然适合需要随时间调整策略的场景 |
| **复杂目标** | 可通过奖励函数设计融合多个复杂目标 |
| **模拟验证** | 可通过历史数据模拟验证策略效果 |
| **自适应性** | 学习到的策略可自动适应不同赛季特点 |

#### 5.2.3 创新点（美赛高奖关键）

1. **赛程感知权重**：学习根据比赛阶段（初赛/半决赛/决赛）自动调整权重的策略
2. **争议预防机制**：在奖励函数中加入"避免争议结果"的惩罚项
3. **反事实策略评估**：评估"如果历史上采用RL策略，Bobby Bones事件能否避免"
4. **可解释策略提取**：从学习到的策略中提取简洁规则，便于实际操作

#### 5.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **样本效率低** | RL需要大量交互样本 | 使用模型-based RL或离线RL |
| **奖励工程困难** | 奖励函数设计需要领域知识 | 基于问题1-3的分析结论设计奖励 |
| **策略不稳定** | 训练过程可能不收敛 | 采用稳定算法（如PPO/SAC） |
| **过拟合历史** | 可能过度适应历史数据 | 采用正则化和早停策略 |

---

### 5.3 问题4可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题4：新投票系统设计流程图                                │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：问题1-3的全部分析结论                                                   │
│ 设计目标：                                                                   │
│   - 公平性：技能与结果的一致性                                                │
│   - 专业性：评委专业意见的权重保护                                            │
│   - 参与度：粉丝投票的有效影响力                                              │
│   - 观赏性：比赛结果的悬念和吸引力                                            │
│ 输出：多目标优化问题定义                                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：指标量化                                                            │
│   - 公平性指标：基于问题2的偏向性分析结果                                     │
│   - 争议度指标：历史争议案例的量化特征                                        │
│   - 观赏性代理：比赛悬念度（排名变化频率）                                    │
│ 步骤2.2：历史数据整理                                                        │
│   - 构建34季的完整比赛模拟数据集                                             │
│ 输出：优化问题的目标函数参数                                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：状态特征构建（RL方案）                                              │
│   - 周次编码、剩余选手数、评分分布统计量                                      │
│ 步骤3.2：约束条件构建（优化方案）                                            │
│   - 权重非负、和为1、变化平滑性约束                                          │
│ 输出：优化问题的完整数学形式                                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：多目标优化│       │ 方案2：强化学习 │                   │
│ ├─目标函数定义  │       │ ├─环境模拟器    │                   │
│ ├─帕累托求解器  │       │ ├─策略网络设计  │                   │
│ └─方案筛选规则  │       │ └─奖励函数设计  │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：方案生成                                                            │
│   - 多目标优化：生成帕累托前沿                                               │
│   - 强化学习：训练策略网络（1000 episodes）                                  │
│ 步骤5.2：方案评估                                                            │
│   - 决策：方案是否可操作？                                                   │
│     → 否：添加约束条件，重新求解                                             │
│   - 决策：策略是否收敛？                                                     │
│     → 否：调整超参数，继续训练                                               │
│ 输出：候选方案集 + 策略网络                                                  │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：历史回测                                                            │
│   - 用新系统模拟34季比赛，对比实际结果                                        │
│   - 计算争议案例减少率、公平性提升度                                          │
│ 步骤6.2：敏感性分析                                                          │
│   - 测试新系统对极端情况的鲁棒性                                             │
│ 步骤6.3：方案对比可视化                                                      │
│   - 帕累托前沿图 + 新旧系统对比雷达图                                         │
│ 输出：最终方案 + 采纳论证报告 + 备忘录素材                                   │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 5.4 最终采用方案：强化学习+动态权重调整机制（方案二）

#### 5.4.1 采用理由

问题4最终采用**方案二：强化学习+动态权重调整机制**，主要基于以下考量：

| 决策因素 | 方案一局限 | 方案二优势 |
|----------|-----------|-----------|
| **动态适应性** | 帕累托优化产出静态权重 | RL可学习随比赛进程动态调整的策略 |
| **目标融合能力** | 多目标优化难以处理非线性目标 | 奖励函数可灵活设计复杂目标组合 |
| **争议预防** | 无法主动预防争议情况 | 可在奖励中加入争议惩罚项 |
| **创新性** | 帕累托优化较为常规 | 强化学习在美赛中具有高创新性 |
| **反事实评估** | 仅能输出备选方案 | 可模拟评估历史争议能否避免 |

#### 5.4.2 强化学习环境设计

**状态空间（State）**：
| 状态变量 | 描述 | 取值范围 |
|----------|------|---------|
| 当前周次 | 比赛进行到第几周 | 1-11 |
| 剩余选手数 | 当前周剩余参赛选手 | 3-16 |
| 评委评分分布 | 当周评委评分的均值/方差/偏度 | 连续值 |
| 评分差距指标 | 最高分与最低分的差距 | 连续值 |
| 历史争议标记 | 是否曾出现争议淘汰 | 0/1 |
| 赛季阶段 | 初赛/半决赛/决赛 | 离散类别 |

**动作空间（Action）**：
| 动作 | 描述 | 实现方式 |
|------|------|---------|
| 评委权重 | 评委投票在合并中的权重 | 连续值：[0.3, 0.8] |
| 粉丝权重 | 粉丝投票在合并中的权重 | 1 - 评委权重 |
| 淘汰规则 | 是否启用评委决定机制 | 离散：0/1 |

**奖励函数设计**：
$$R = w_1 \cdot \text{公平性指标} + w_2 \cdot \text{观赏性指标} - w_3 \cdot \text{争议惩罚}$$

其中：
- **公平性指标**：淘汰选手的评委排名（排名越低越公平）
- **观赏性指标**：排名变化的悬念度（变化越多越有观赏性）
- **争议惩罚**：当评委倒数但晋级时触发（基于Bobby Bones类情况）

#### 5.4.3 算法选择与训练策略

**推荐算法**：Proximal Policy Optimization（PPO）

| 选择理由 | 说明 |
|----------|------|
| 稳定性 | PPO通过clip机制保证策略更新稳定 |
| 样本效率 | 相比TRPO更高效 |
| 实现成熟 | Stable-baselines3提供开箱即用的实现 |
| 连续动作 | 天然支持连续动作空间（权重配置） |

**训练策略**：
```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    强化学习训练流程                                          │
└─────────────────────────────────────────────────────────────────────────────┘

步骤1：环境构建
    │
    ├─ 基于34季历史数据构建比赛模拟器
    ├─ 实现状态转移逻辑（淘汰→下一周）
    └─ 实现奖励计算函数
    │
    ▼
步骤2：策略网络初始化
    │
    ├─ 网络结构：2层全连接（128-64神经元）
    ├─ 激活函数：ReLU
    └─ 输出层：评委权重（Sigmoid归一化到[0.3,0.8]）
    │
    ▼
步骤3：训练迭代
    │
    ├─ 每个episode模拟一个完整赛季
    ├─ 总训练episodes：10000
    ├─ 学习率：3e-4
    └─ 折扣因子γ：0.99
    │
    ▼
步骤4：收敛诊断
    │
    ├─ 监控平均奖励曲线
    ├─ 决策：奖励是否收敛？
    │   → 否：调整奖励权重或网络结构
    │   → 是：进入评估阶段
    │
    ▼
步骤5：策略评估
    │
    ├─ 在保留的测试赛季上评估策略
    ├─ 计算争议案例避免率
    └─ 与历史规则对比
```

#### 5.4.4 反事实历史评估

针对4个争议案例，评估"如果采用RL策略能否避免争议"：

| 争议案例 | 历史规则下结果 | RL策略模拟结果 | 是否避免争议 |
|----------|---------------|---------------|-------------|
| Jerry Rice (S2) | 5周评委最低仍获亚军 | 模拟待评估 | 待验证 |
| Billy Ray Cyrus (S4) | 5周评委最低分 | 模拟待评估 | 待验证 |
| Bristol Palin (S11) | 12次评委最低，排名第三 | 模拟待评估 | 待验证 |
| Bobby Bones (S27) | 评委低分却获胜 | 模拟待评估 | 待验证 |

#### 5.4.5 可解释策略提取

从训练好的RL策略中提取简洁规则，便于实际操作：

**预期规则示例**：
1. **初赛阶段（周1-4）**：评委权重50%，粉丝权重50%
2. **半决赛阶段（周5-8）**：评委权重60%，粉丝权重40%
3. **决赛阶段（周9-11）**：评委权重70%，粉丝权重30%
4. **争议触发条件**：当评委最低分选手的粉丝排名在前30%时，启用评委决定机制

#### 5.4.6 预期输出

| 输出项 | 描述 | 用途 |
|--------|------|------|
| 训练奖励曲线 | 展示策略学习过程 | 论文Figure |
| 动态权重策略表 | 不同状态下的权重配置 | 论文Table |
| 反事实评估结果 | 历史争议能否避免 | 论文核心论证 |
| 简洁决策规则 | 从RL策略提取的可操作规则 | 备忘录内容 |
| 新旧系统对比雷达图 | 多维度性能对比 | 论文Figure |

---

## 六、模型选择汇总表

### 6.1 各问题最终采用方案

| 问题 | 最终采用方案 | 核心工具 | 输出形式 | 美赛适配亮点 |
|------|-------------|---------|---------|-------------|
| **问题1** | **双方案结合**：约束优化+贝叶斯推断 | CVXPY + PyMC3 | 点估计+后验分布 | Placement约束+概率化建模 |
| **问题2** | **方案二**：随机森林+SHAP | Scikit-learn/SHAP | 特征贡献+局部解释 | 可解释AI+争议案例分析 |
| **问题3** | **双方案结合**：多元回归+XGBoost | Statsmodels + XGBoost | 系数表+SHAP图 | 名人特征定义+差异化分析 |
| **问题4** | **方案二**：强化学习+动态权重 | Stable-baselines3 | 自适应策略 | 反事实评估+争议预防 |

### 6.2 各问题模型对照（完整）

| 问题 | 方案类型 | 模型名称 | 核心工具 | 输出形式 | 美赛适配亮点 |
|------|---------|---------|---------|---------|-------------|
| 问题1 | 基础 | 约束线性规划+Bootstrap | CVXPY/Scipy | 投票估算+置信区间 | 分阶段建模+确定性度量 |
| 问题1 | 创新 | 贝叶斯推断+MCMC | PyMC3/Stan | 后验分布+层次结构 | 概率化建模+信息先验 |
| 问题2 | ~~基础~~ | ~~配对检验+效应量~~ | - | - | *未采用* |
| 问题2 | **创新** | **随机森林+SHAP** | Scikit-learn/SHAP | 特征贡献+因果分析 | 可解释AI+反事实分析 |
| 问题3 | 基础 | 多元回归+逐步选择 | Statsmodels | 回归系数表 | 交互项+稳健估计 |
| 问题3 | 创新 | XGBoost+SHAP | XGBoost/SHAP | 重要性排序+依赖图 | 分层SHAP+时序演化 |
| 问题4 | ~~基础~~ | ~~多目标优化+帕累托~~ | - | - | *未采用* |
| 问题4 | **创新** | **强化学习+动态调整** | Stable-baselines3 | 自适应策略 | 赛程感知+争议预防 |

### 6.3 最终实施策略

基于本次模型选择，确定以下实施策略：

| 问题 | 实施策略 | 关键约束/特征 | 核心输出 |
|------|---------|--------------|---------|
| 问题1 | 双方案并行，结果互验 | **Placement约束条件** | 粉丝投票估算表+置信区间 |
| 问题2 | 单方案深度实施 | 争议案例SHAP分析 | 方法对比+推荐论证 |
| 问题3 | 双方案并行，聚焦**名人特征** | 年龄/行业/地域/国籍 | 特征重要性+差异化影响 |
| 问题4 | 单方案创新突破 | RL环境+奖励设计 | 动态策略+反事实验证 |

**实施优先级**：
1. ✅ 问题1（核心基础）：双方案结合，确保粉丝投票估算可靠
2. ✅ 问题3（特征分析）：双方案结合，明确名人特征影响
3. ✅ 问题2（方法对比）：方案二深度实施，争议案例SHAP分析
4. ✅ 问题4（创新设计）：方案二深度实施，RL策略优化

---

## 七、参考工具与库

| 模型类别 | Python库 | R语言包 | 备注 |
|----------|---------|--------|------|
| 约束优化 | CVXPY, Scipy.optimize | lpSolve, quadprog | 支持线性/二次规划 |
| 贝叶斯推断 | PyMC3, Stan, NumPyro | RStan, brms | MCMC采样 |
| 统计检验 | Scipy.stats, Statsmodels | stats, car | 假设检验 |
| 随机森林 | Scikit-learn | randomForest | 集成学习 |
| XGBoost | xgboost, lightgbm | xgboost | 梯度提升 |
| SHAP | shap | shapr | 可解释性 |
| 多目标优化 | Pymoo, DEAP | mco | 帕累托优化 |
| 强化学习 | Stable-baselines3, RLlib | - | RL算法 |

---

**文档生成时间**：2026年MCM竞赛

**适用对象**：2026年MCM C题参赛团队

**文档版本**：v1.1

**更新日志**：
- v1.1：根据团队讨论确定各问题最终采用方案
  - 问题1：双方案结合，添加Placement约束条件详解
  - 问题2：采用方案二（随机森林+SHAP）
  - 问题3：双方案结合，明确名人特征定义与分类
  - 问题4：采用方案二（强化学习+动态权重）
- v1.0：初始版本，包含所有问题的基础+创新双方案

**关联模块**：问题分析模块.md
