# 模型选择模块

## 2026年MCM问题C：与星共舞（Dancing with the Stars）模型选择方案

---

## 一、模型选择总览

本模块针对四个核心问题，分别推荐**基础适配方案（保分核心）**和**创新融合方案（冲奖关键）**两种模型策略，确保既有稳定可靠的基础分析，又有突出创新的高分亮点。

| 问题 | 基础方案（保分核心） | 创新方案（冲奖关键） |
|------|---------------------|---------------------|
| 问题1：粉丝投票估算 | 约束线性规划+Bootstrap采样 | 贝叶斯推断+MCMC采样融合 |
| 问题2：方法对比分析 | 配对t检验+Wilcoxon秩和检验 | 随机森林+SHAP可解释分析 |
| 问题3：特征影响分析 | 多元线性回归+逐步回归特征筛选 | XGBoost+SHAP值特征重要性分析 |
| 问题4：新系统设计 | 多目标线性规划+帕累托优化 | 强化学习+动态权重调整机制 |

---

## 二、问题1：粉丝投票估算模型

### 2.1 方案1：约束线性规划+Bootstrap采样（基础适配方案）

#### 2.1.1 核心原理

约束线性规划模型通过建立评委评分与粉丝投票之间的线性映射关系，在满足排名/淘汰约束条件下，反推最可能的粉丝投票数分布。具体而言：

- **数学建模思路**：设第$i$位选手第$w$周的粉丝投票数为$V_{i,w}$，评委总分为$J_{i,w}$。根据题目规则，粉丝投票百分比$P_{fan}^{(i)}$与评委评分百分比$P_{judge}^{(i)}$按某种权重合并计算总分，决定淘汰顺序。我们将这一过程建模为：
  $$\min \sum_{i,w} (V_{i,w} - \hat{V}_{i,w})^2$$
  约束条件包括：排名约束（淘汰者的总分最低）、非负约束（$V_{i,w} \geq 0$）、百分比归一化约束（$\sum_i P_{fan}^{(i)} = 1$）。

- **Bootstrap采样增强**：由于粉丝投票存在多解性，采用Bootstrap重采样方法（1000次采样），对每次采样数据求解优化问题，最终统计粉丝投票估算值的均值和置信区间，量化估算的确定性。

#### 2.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **数据字段匹配** | 核心输入为`week*_judge*_score`（连续数值），目标输出为粉丝投票估算值，完美匹配线性规划模型的输入输出结构 |
| **规则约束体现** | 可灵活处理三个时期（排名法/百分比法/评委决定法）的不同规则，通过调整约束条件实现规则切换 |
| **单/多维度覆盖** | 单维度：逐周求解；多维度：跨周联合优化，考虑选手累积表现趋势 |
| **缺失值处理** | 对N/A值（第4评委缺席）和0值（已淘汰选手）通过约束条件自然处理 |

#### 2.1.3 创新点（美赛适配改进）

1. **分阶段约束建模**：根据赛季1-2（排名法）、3-27（百分比法）、28-34（排名法+评委决定）三个时期，设计差异化约束函数，精确还原规则变化
2. **Bootstrap确定性度量**：引入Bootstrap采样量化估算不确定性，输出置信区间而非单一点估计，增强结论可信度
3. **松弛变量引入**：在硬约束基础上引入松弛变量，允许模型在边界情况下有限度偏离，提升模型鲁棒性

#### 2.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **多解问题** | 粉丝投票数存在无穷多可行解 | 添加正则化项（如最小化投票数方差），引导解向合理区间收敛 |
| **线性假设局限** | 实际投票行为可能非线性 | 引入分段线性或二次项扩展模型 |
| **对异常值敏感** | 争议案例（如Bobby Bones）可能导致优化失败 | 采用鲁棒优化方法，对异常周数据降权处理 |
| **计算复杂度** | Bootstrap需多次求解优化问题 | 采用warm-start策略，复用上一次解作为初始点 |

---

### 2.2 方案2：贝叶斯推断+MCMC采样融合（创新融合方案）

#### 2.2.1 核心原理

贝叶斯推断模型将粉丝投票数视为待估计的隐变量，通过建立生成模型描述"粉丝投票→合并计算→淘汰结果"的正向过程，利用马尔可夫链蒙特卡洛（MCMC）方法从后验分布中采样，获得粉丝投票数的概率分布估计。

- **生成模型构建**：
  - 先验分布：假设粉丝投票数服从某种分布（如正态分布或Dirichlet分布），反映对投票行为的先验认知
  - 似然函数：给定粉丝投票和评委评分，计算观察到实际淘汰结果的概率
  - 后验分布：通过贝叶斯公式，结合先验和似然更新对粉丝投票的估计

- **MCMC采样**：采用Gibbs采样或Metropolis-Hastings算法，从高维后验分布中采样，生成大量粉丝投票数的样本，统计其分布特征（均值、方差、分位数）。

#### 2.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **数据字段匹配** | 核心数据为评委评分（连续型）和淘汰结果（离散型），贝叶斯模型天然支持混合类型数据建模 |
| **不确定性量化** | 直接输出后验分布，自然给出置信区间和确定性度量，完美契合题目对"确定性"的要求 |
| **规则嵌入** | 通过似然函数设计灵活嵌入不同时期的合并规则 |
| **层次建模** | 可构建层次贝叶斯模型，区分赛季级别、选手级别、周级别的投票模式差异 |

#### 2.2.3 创新点（美赛高奖关键）

1. **概率化建模范式**：区别于传统的点估计方法，贝叶斯方法输出完整的概率分布，体现对数据不确定性的深刻理解
2. **层次贝叶斯结构**：构建赛季→选手→周的层次结构，捕捉不同层级的投票模式差异
3. **信息先验融合**：将行业知识（如热门行业选手可能获得更多投票）融入先验分布，增强模型的解释性和预测精度
4. **收敛诊断可视化**：通过MCMC收敛诊断（Gelman-Rubin统计量、迹图）展示估计过程的可靠性

#### 2.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **计算成本高** | MCMC采样需大量迭代 | 采用高效采样算法（如NUTS），或使用变分推断作为替代 |
| **先验敏感性** | 不当的先验设置影响后验结果 | 进行先验敏感性分析，比较不同先验下的结果一致性 |
| **模型复杂度** | 层次模型参数众多 | 采用模型比较准则（WAIC/LOO-CV）选择最优模型复杂度 |
| **收敛困难** | 高维空间采样可能不收敛 | 增加采样链数量，延长burn-in期，使用自适应采样策略 |

---

### 2.3 问题1可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题1：粉丝投票估算模型流程图                              │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：评委评分矩阵 (421选手 × 11周 × 4评委)                                   │
│ 输出：数据抽象模型 → 选手-周-评分三维张量                                      │
│ 决策：是否按赛季规则分组？→ 是：分为三组（1-2季/3-27季/28-34季）               │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：缺失值处理                                                          │
│   - N/A值（第4评委缺席）→ 标记为缺失，计算时排除                              │
│   - 0值（已淘汰选手）→ 标记为非参与状态                                       │
│ 步骤2.2：评分归一化                                                          │
│   - 计算各周各选手的评委总分                                                  │
│   - 转换为百分比/排名形式                                                    │
│ 输出：预处理后的评分矩阵 + 淘汰标签向量                                       │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：评分特征提取                                                        │
│   - 周评委总分、累积评分、评分趋势（上升/下降）                               │
│ 步骤3.2：赛季规则编码                                                        │
│   - 排名法标记（赛季1-2, 28-34）                                             │
│   - 百分比法标记（赛季3-27）                                                 │
│ 输出：特征矩阵 X (n×d维)                                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：约束优化  │       │ 方案2：贝叶斯推断│                   │
│ ├─目标函数设计   │       │ ├─先验分布设定   │                   │
│ ├─约束条件构建   │       │ ├─似然函数构建   │                   │
│ └─求解器选择     │       │ └─MCMC采样配置   │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：模型求解/采样                                                       │
│   - 约束优化：使用CVXPY/Scipy求解器                                          │
│   - 贝叶斯推断：运行MCMC采样（10000次迭代，burn-in=2000）                     │
│ 步骤5.2：收敛检验                                                            │
│   - 决策：模型是否收敛？                                                     │
│     → 否：调整参数（正则化系数/先验超参数），返回步骤5.1                       │
│     → 是：进入结果验证                                                       │
│ 输出：粉丝投票估算值 + 采样分布                                              │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：一致性检验                                                          │
│   - 模型预测淘汰结果 vs 实际淘汰结果                                          │
│   - 计算准确率、Kappa系数、混淆矩阵                                           │
│ 步骤6.2：确定性评估                                                          │
│   - 计算95%置信区间                                                          │
│   - 评估逐选手/逐周的确定性差异                                              │
│ 决策：一致性是否达标（>80%）？                                               │
│   → 否：回溯调整模型结构，返回阶段4                                           │
│   → 是：输出最终结果                                                         │
│ 输出：一致性指标图 + 置信区间图 + 确定性分层报告                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 三、问题2：投票合并方法对比分析

### 3.1 方案1：配对t检验+Wilcoxon秩和检验（基础适配方案）

#### 3.1.1 核心原理

配对检验方法通过统计假设检验框架，量化分析排名法和百分比法产生结果的显著性差异。

- **配对t检验**：针对两种方法下同一选手的最终排名/得分，计算配对差异的均值是否显著异于零
  $$t = \frac{\bar{d}}{s_d/\sqrt{n}}$$
  其中$\bar{d}$为配对差异均值，$s_d$为标准差，$n$为样本量。

- **Wilcoxon秩和检验**：作为非参数替代方案，不依赖正态分布假设，对排名数据更为适用。通过比较两种方法产生的排名分布差异，计算W统计量和p值。

- **效应量计算**：采用Cohen's d或秩双列相关系数量化差异的实际意义大小，避免仅依赖p值判断。

#### 3.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **数据类型匹配** | 排名数据为有序离散型，Wilcoxon检验专为此类数据设计 |
| **配对设计** | 同一选手在两种规则下的表现构成天然配对，减少个体差异干扰 |
| **假设检验框架** | 输出p值和置信区间，符合学术论文规范 |
| **争议案例分析** | 可针对特定选手计算其在两种方法下的差异Z-score |

#### 3.1.3 创新点（美赛适配改进）

1. **分层配对检验**：按赛季、周数、选手行业分层进行配对检验，识别差异的主要来源
2. **多重检验校正**：采用Bonferroni或FDR方法校正多重比较问题，控制假阳性率
3. **效应量可视化**：绘制效应量森林图，直观展示不同维度的差异大小

#### 3.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **正态假设敏感** | t检验依赖正态分布假设 | 优先使用Wilcoxon非参数检验 |
| **仅能检测差异** | 无法解释差异来源 | 结合回归分析探索影响因素 |
| **对极端值敏感** | 争议案例可能主导检验结果 | 进行稳健性分析（剔除极端值后重测） |

---

### 3.2 方案2：随机森林+SHAP可解释分析（创新融合方案）

#### 3.2.1 核心原理

随机森林分类器结合SHAP（SHapley Additive exPlanations）可解释性分析，不仅能预测两种方法产生的结果差异，还能深入揭示导致差异的关键因素。

- **随机森林建模**：以"两种方法是否产生不同淘汰结果"为目标变量（二分类），特征包括评委评分、选手特征、赛季周数等，训练随机森林分类器。

- **SHAP值分析**：利用博弈论中的Shapley值原理，计算每个特征对预测结果的边际贡献，生成全局和局部的可解释性报告：
  - 全局重要性：哪些因素最能解释两种方法的差异
  - 局部解释：争议案例（如Bobby Bones）中各因素的具体贡献

#### 3.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **特征多样性** | 可同时处理连续（评分）、离散（行业）、有序（排名）等多种特征类型 |
| **非线性捕捉** | 随机森林可捕捉评分与差异之间的非线性关系 |
| **可解释性** | SHAP提供直观的特征贡献可视化，满足论文图表需求 |
| **争议案例分析** | 可针对单个案例生成局部解释，精准分析争议来源 |

#### 3.2.3 创新点（美赛高奖关键）

1. **因果推断视角**：结合反事实分析（Counterfactual）探索"如果采用另一种方法，该选手排名会如何变化"
2. **交互效应挖掘**：通过SHAP交互图发现特征间的协同效应（如高评分+热门行业的组合效应）
3. **偏向性量化**：定义偏向粉丝/评委的SHAP-based指数，量化两种方法的系统性偏差
4. **动态可视化**：制作SHAP瀑布图、蜂群图等高质量可视化，提升论文图表档次

#### 3.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **样本量要求** | 随机森林需要足够样本量 | 采用重采样或数据增强技术 |
| **过拟合风险** | 特征过多可能导致过拟合 | 使用交叉验证和特征选择 |
| **SHAP计算成本** | 精确SHAP值计算复杂度高 | 采用TreeSHAP等近似算法 |
| **因果解释限制** | SHAP反映相关性而非因果性 | 论文中明确区分相关性与因果性解释 |

---

### 3.3 问题2可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题2：投票合并方法对比分析流程图                          │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：问题1的粉丝投票估算结果 + 评委评分数据                                  │
│ 输出：两种方法的对比数据框架                                                 │
│   - 排名法计算引擎：基于排名合并计算总分                                      │
│   - 百分比法计算引擎：基于百分比合并计算总分                                  │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：方法结果计算                                                        │
│   - 对全部选手×周，分别用两种方法计算合并得分                                 │
│ 步骤2.2：差异标记                                                            │
│   - 标记两种方法产生不同淘汰结果的周次                                        │
│   - 提取4个争议案例数据                                                      │
│ 输出：对比数据矩阵 + 争议案例子集                                            │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：差异特征构建                                                        │
│   - 排名差异 = 排名法排名 - 百分比法排名                                     │
│   - 得分差异 = 排名法得分 - 百分比法得分                                     │
│ 步骤3.2：上下文特征                                                          │
│   - 选手当周评委排名、累积评分、行业类别                                     │
│ 输出：特征矩阵（含差异特征和上下文特征）                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：配对检验  │       │ 方案2：RF+SHAP  │                   │
│ ├─配对t检验     │       │ ├─随机森林训练  │                   │
│ ├─Wilcoxon检验  │       │ ├─SHAP值计算    │                   │
│ └─效应量计算    │       │ └─交互效应分析  │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：统计检验执行                                                        │
│   - 计算t统计量、W统计量、p值                                                │
│   - 应用多重检验校正                                                         │
│ 步骤5.2：机器学习训练                                                        │
│   - 5折交叉验证训练随机森林                                                  │
│   - 决策：模型是否过拟合（训练-测试AUC差距>0.1）？                            │
│     → 是：增加正则化（减少树深度/增加min_samples）                           │
│     → 否：计算SHAP值                                                        │
│ 输出：检验统计量 + 随机森林模型 + SHAP值矩阵                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：差异显著性报告                                                      │
│   - 生成p值汇总表、效应量森林图                                              │
│ 步骤6.2：争议案例深度分析                                                    │
│   - 4个争议案例的SHAP瀑布图                                                  │
│   - 反事实模拟："如果用另一种方法会怎样"                                     │
│ 步骤6.3：方法推荐论证                                                        │
│   - 基于分析结果给出方法推荐及理由                                           │
│ 输出：对比分析报告 + 争议案例图表 + 方法推荐书                               │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 四、问题3：名人特征影响分析

### 4.1 方案1：多元线性回归+逐步回归特征筛选（基础适配方案）

#### 4.1.1 核心原理

多元线性回归模型建立名人特征（年龄、行业、地域等）与比赛结果（评委评分/粉丝投票/最终排名）之间的线性关系：
$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p + \epsilon$$

- **逐步回归特征筛选**：采用前向选择（Forward Selection）或后向消除（Backward Elimination）策略，基于AIC/BIC准则自动选择最优特征子集，避免多重共线性问题。

- **分层回归分析**：分别建立对评委评分和粉丝投票的回归模型，比较同一特征在两个模型中的系数差异，揭示特征对评委vs粉丝的差异化影响。

#### 4.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **特征类型处理** | 类别特征（行业、州）通过哑变量编码转换为数值型 |
| **系数可解释性** | 回归系数直接反映特征的边际影响，易于论文阐述 |
| **显著性检验** | 每个特征的t检验p值支持假设检验结论 |
| **差异化分析** | 通过对比两个回归模型的系数差异，实现对评委vs粉丝的差异化影响分析 |

#### 4.1.3 创新点（美赛适配改进）

1. **交互项建模**：引入年龄×行业、行业×地域等交互项，捕捉特征间的协同效应
2. **稳健标准误**：采用异方差稳健标准误（HC3），增强统计推断的稳健性
3. **分层对比设计**：构建评委评分模型和粉丝投票模型的系数对比表，直观展示差异化影响

#### 4.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **线性假设** | 特征与结果可能非线性相关 | 引入多项式项或分箱处理 |
| **多重共线性** | 类别特征编码后可能高度相关 | 采用VIF检验，删除高共线性变量 |
| **高维稀疏** | 类别特征编码后维度爆炸 | 采用正则化回归（Ridge/LASSO） |
| **缺失值敏感** | 补充数据存在大量缺失 | 仅将补充数据作为辅助验证 |

---

### 4.2 方案2：XGBoost+SHAP值特征重要性分析（创新融合方案）

#### 4.2.1 核心原理

XGBoost（eXtreme Gradient Boosting）是一种高效的梯度提升树集成算法，结合SHAP值分析，可实现高精度预测与深度可解释性的完美结合。

- **XGBoost建模**：以最终排名或投票比例为目标变量，名人特征为输入，训练XGBoost模型。通过梯度提升策略，逐步构建多棵决策树，每棵树学习前序模型的残差。

- **SHAP值特征重要性**：
  - **全局重要性**：计算各特征的平均绝对SHAP值，得到全局特征重要性排序
  - **局部解释**：对单个选手的预测结果，分解各特征的贡献
  - **依赖图**：展示特征值与SHAP值的关系，揭示非线性效应

#### 4.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **特征类型** | 天然支持数值和类别特征，无需复杂编码 |
| **非线性建模** | 决策树集成可捕捉复杂的非线性关系 |
| **缺失值处理** | XGBoost内置缺失值处理机制，自动学习最优分裂方向 |
| **特征交互** | 自动学习特征间的交互效应，无需手动构建交互项 |

#### 4.2.3 创新点（美赛高奖关键）

1. **SHAP依赖图创新应用**：绘制年龄-SHAP值依赖图，揭示"最佳参赛年龄区间"
2. **特征交互SHAP分析**：计算特征对的交互SHAP值，发现如"体育行业×年轻选手"的正向协同效应
3. **时序演化分析**：按赛季分组训练模型，分析特征重要性的时序演化趋势
4. **对评委vs粉丝的分层SHAP**：分别建立评委评分预测模型和粉丝投票预测模型，对比同一特征在两个模型中的SHAP值差异

#### 4.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **过拟合风险** | 树模型容易过拟合 | 采用早停法、L1/L2正则化、限制树深度 |
| **超参数敏感** | 性能依赖超参数设置 | 使用Optuna/GridSearch进行超参数调优 |
| **因果推断限制** | SHAP反映相关性 | 结合领域知识解读，明确声明相关性而非因果性 |
| **补充数据局限** | 社交粉丝数据覆盖率低 | 作为辅助特征使用，主模型基于核心数据 |

---

### 4.3 问题3可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题3：名人特征影响分析流程图                              │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：名人特征数据 + 问题1粉丝投票估算 + 评委评分                             │
│ 目标变量：                                                                   │
│   - Y1：评委总评分（反映评委偏好）                                            │
│   - Y2：粉丝投票估算值（反映粉丝偏好）                                        │
│   - Y3：最终排名（综合表现）                                                  │
│ 输出：多目标特征影响分析框架                                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：核心数据处理                                                        │
│   - 年龄：保留原始数值，检验分布形态                                          │
│   - 行业：哑变量编码或目标编码                                               │
│   - 地域：按人口/地域分组降维                                                │
│ 步骤2.2：补充数据处理（辅助）                                                │
│   - 社交粉丝数：对数变换，处理长尾分布                                        │
│   - 缺失值：标记为单独类别或使用多重插补                                      │
│ 输出：清洗后的特征数据框                                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：基础特征构建                                                        │
│   - 年龄分箱：青年(<30)/中年(30-45)/成熟(>45)                                │
│   - 行业分组：娱乐/体育/政治/其他                                            │
│   - 地域分组：东部/西部/南部/北部/非美国                                      │
│ 步骤3.2：交互特征构建                                                        │
│   - 年龄×行业、行业×地域                                                     │
│ 步骤3.3：舞者特征提取                                                        │
│   - 舞者历史胜率、舞者参赛次数                                               │
│ 输出：完整特征矩阵 (n×p维)                                                   │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：线性回归  │       │ 方案2：XGBoost  │                   │
│ ├─逐步回归       │       │ ├─超参数设置    │                   │
│ ├─VIF检验        │       │ ├─交叉验证配置  │                   │
│ └─稳健标准误     │       │ └─SHAP配置      │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：模型训练                                                            │
│   - 线性回归：OLS估计，逐步选择最优变量                                       │
│   - XGBoost：5折CV，早停法防过拟合                                           │
│ 步骤5.2：模型诊断                                                            │
│   - 决策：是否存在多重共线性（VIF>10）？                                      │
│     → 是：剔除高共线变量或采用Ridge回归                                       │
│   - 决策：XGBoost是否过拟合？                                                │
│     → 是：增加正则化参数，减少迭代次数                                        │
│ 输出：回归系数表 + XGBoost模型 + 训练曲线                                    │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：特征重要性输出                                                      │
│   - 回归系数显著性表（含p值、置信区间）                                       │
│   - SHAP全局重要性条形图                                                     │
│   - SHAP依赖图（年龄、行业等核心特征）                                        │
│ 步骤6.2：差异化影响对比                                                      │
│   - 评委模型 vs 粉丝模型 的特征重要性对比图                                   │
│   - 发现差异化特征（如某行业对粉丝吸引力强但评委不认可）                       │
│ 步骤6.3：交叉验证稳定性                                                      │
│   - 5折CV下的特征重要性一致性检验                                            │
│ 输出：特征重要性排序表 + 热力图 + 差异化分析报告                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 五、问题4：新投票系统设计

### 5.1 方案1：多目标线性规划+帕累托优化（基础适配方案）

#### 5.1.1 核心原理

多目标优化模型同时考虑公平性、评委专业性保护、粉丝参与度等多个目标，设计最优的投票合并权重方案。

- **目标函数设计**：
  - 目标1（公平性）：最小化低评分选手晋级概率
  - 目标2（专业性）：最大化评委评分权重
  - 目标3（参与度）：最大化粉丝投票影响力

- **帕累托优化**：由于目标间存在冲突，采用帕累托前沿分析，找到所有非劣解（Pareto Optimal Solutions），提供多个方案供决策者选择。

- **约束条件**：权重非负、权重和为1、规则可操作性约束等。

#### 5.1.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **多目标平衡** | 帕累托优化天然适合多目标冲突场景 |
| **可解释性** | 每个帕累托解对应明确的权重配置 |
| **回测验证** | 可用历史数据验证各方案效果 |
| **灵活性** | 可根据节目需求调整目标权重 |

#### 5.1.3 创新点（美赛适配改进）

1. **公平性指标创新定义**：基于问题2和问题3的分析结果，定义"技能-结果一致性指数"作为公平性度量
2. **动态权重机制**：设计随比赛进程调整的动态权重（如决赛周增加评委权重）
3. **多情景分析**：生成多个帕累托方案，对比分析各方案的优劣势

#### 5.1.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **目标量化困难** | 公平性等抽象概念难以量化 | 基于问题1-3的分析结果构建代理指标 |
| **帕累托解过多** | 可能产生大量非劣解 | 采用聚类方法筛选代表性方案 |
| **线性假设** | 实际投票行为可能非线性 | 引入分段线性或非线性目标函数 |

---

### 5.2 方案2：强化学习+动态权重调整机制（创新融合方案）

#### 5.2.1 核心原理

强化学习（Reinforcement Learning）框架将投票系统设计建模为序贯决策问题，通过模拟比赛过程学习最优的动态权重调整策略。

- **状态空间**：当前周次、剩余选手数量、评委评分分布、历史投票趋势等
- **动作空间**：评委-粉丝投票的权重配置（如评委60%-粉丝40%）
- **奖励函数**：综合公平性、观赏性、粉丝满意度等指标

- **策略学习**：使用Q-Learning或Policy Gradient方法，学习状态到最优动作的映射，实现权重的动态调整。

#### 5.2.2 适配性分析

| 适配维度 | 说明 |
|----------|------|
| **动态决策** | RL天然适合需要随时间调整策略的场景 |
| **复杂目标** | 可通过奖励函数设计融合多个复杂目标 |
| **模拟验证** | 可通过历史数据模拟验证策略效果 |
| **自适应性** | 学习到的策略可自动适应不同赛季特点 |

#### 5.2.3 创新点（美赛高奖关键）

1. **赛程感知权重**：学习根据比赛阶段（初赛/半决赛/决赛）自动调整权重的策略
2. **争议预防机制**：在奖励函数中加入"避免争议结果"的惩罚项
3. **反事实策略评估**：评估"如果历史上采用RL策略，Bobby Bones事件能否避免"
4. **可解释策略提取**：从学习到的策略中提取简洁规则，便于实际操作

#### 5.2.4 局限性与规避方案

| 局限性 | 问题描述 | 规避方案 |
|--------|----------|----------|
| **样本效率低** | RL需要大量交互样本 | 使用模型-based RL或离线RL |
| **奖励工程困难** | 奖励函数设计需要领域知识 | 基于问题1-3的分析结论设计奖励 |
| **策略不稳定** | 训练过程可能不收敛 | 采用稳定算法（如PPO/SAC） |
| **过拟合历史** | 可能过度适应历史数据 | 采用正则化和早停策略 |

---

### 5.3 问题4可视化流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    问题4：新投票系统设计流程图                                │
└─────────────────────────────────────────────────────────────────────────────┘

【阶段1：数据场景抽象】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 输入：问题1-3的全部分析结论                                                   │
│ 设计目标：                                                                   │
│   - 公平性：技能与结果的一致性                                                │
│   - 专业性：评委专业意见的权重保护                                            │
│   - 参与度：粉丝投票的有效影响力                                              │
│   - 观赏性：比赛结果的悬念和吸引力                                            │
│ 输出：多目标优化问题定义                                                     │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段2：数据预处理】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤2.1：指标量化                                                            │
│   - 公平性指标：基于问题2的偏向性分析结果                                     │
│   - 争议度指标：历史争议案例的量化特征                                        │
│   - 观赏性代理：比赛悬念度（排名变化频率）                                    │
│ 步骤2.2：历史数据整理                                                        │
│   - 构建34季的完整比赛模拟数据集                                             │
│ 输出：优化问题的目标函数参数                                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段3：特征工程】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤3.1：状态特征构建（RL方案）                                              │
│   - 周次编码、剩余选手数、评分分布统计量                                      │
│ 步骤3.2：约束条件构建（优化方案）                                            │
│   - 权重非负、和为1、变化平滑性约束                                          │
│ 输出：优化问题的完整数学形式                                                 │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段4：模型构建】
    │
    ├─────────────────────────────┬─────────────────────────────┐
    ▼                             ▼                             │
┌─────────────────┐       ┌─────────────────┐                   │
│ 方案1：多目标优化│       │ 方案2：强化学习 │                   │
│ ├─目标函数定义  │       │ ├─环境模拟器    │                   │
│ ├─帕累托求解器  │       │ ├─策略网络设计  │                   │
│ └─方案筛选规则  │       │ └─奖励函数设计  │                   │
└────────┬────────┘       └────────┬────────┘                   │
         │                         │                             │
         └──────────┬──────────────┘                             │
                    ▼                                            │
【阶段5：训练迭代】                                               │
    │                                                            │
    ▼                                                            │
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤5.1：方案生成                                                            │
│   - 多目标优化：生成帕累托前沿                                               │
│   - 强化学习：训练策略网络（1000 episodes）                                  │
│ 步骤5.2：方案评估                                                            │
│   - 决策：方案是否可操作？                                                   │
│     → 否：添加约束条件，重新求解                                             │
│   - 决策：策略是否收敛？                                                     │
│     → 否：调整超参数，继续训练                                               │
│ 输出：候选方案集 + 策略网络                                                  │
└─────────────────────────────────────────────────────────────────────────────┘
    │
    ▼
【阶段6：结果验证】
    │
    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│ 步骤6.1：历史回测                                                            │
│   - 用新系统模拟34季比赛，对比实际结果                                        │
│   - 计算争议案例减少率、公平性提升度                                          │
│ 步骤6.2：敏感性分析                                                          │
│   - 测试新系统对极端情况的鲁棒性                                             │
│ 步骤6.3：方案对比可视化                                                      │
│   - 帕累托前沿图 + 新旧系统对比雷达图                                         │
│ 输出：最终方案 + 采纳论证报告 + 备忘录素材                                   │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 六、模型选择汇总表

### 6.1 各问题模型对照

| 问题 | 方案类型 | 模型名称 | 核心工具 | 输出形式 | 美赛适配亮点 |
|------|---------|---------|---------|---------|-------------|
| 问题1 | 基础 | 约束线性规划+Bootstrap | CVXPY/Scipy | 投票估算+置信区间 | 分阶段建模+确定性度量 |
| 问题1 | 创新 | 贝叶斯推断+MCMC | PyMC3/Stan | 后验分布+层次结构 | 概率化建模+信息先验 |
| 问题2 | 基础 | 配对检验+效应量 | Scipy/Statsmodels | p值+效应量 | 分层检验+多重校正 |
| 问题2 | 创新 | 随机森林+SHAP | Scikit-learn/SHAP | 特征贡献+因果分析 | 可解释AI+反事实分析 |
| 问题3 | 基础 | 多元回归+逐步选择 | Statsmodels | 回归系数表 | 交互项+稳健估计 |
| 问题3 | 创新 | XGBoost+SHAP | XGBoost/SHAP | 重要性排序+依赖图 | 分层SHAP+时序演化 |
| 问题4 | 基础 | 多目标优化+帕累托 | Pymoo/DEAP | 帕累托前沿+方案集 | 动态权重+多情景 |
| 问题4 | 创新 | 强化学习+动态调整 | Stable-baselines3 | 自适应策略 | 赛程感知+争议预防 |

### 6.2 推荐实施策略

**保分策略**：优先完成所有问题的基础方案，确保模型稳定、结果可靠、论述完整。

**冲奖策略**：在基础方案完成后，选择1-2个问题深入实施创新方案，重点打磨可视化和创新点论述。

**建议优先级**：
1. 问题1创新方案（贝叶斯+MCMC）：概率化建模在美赛C题中较为新颖
2. 问题3创新方案（XGBoost+SHAP）：可解释性强，图表丰富
3. 问题2创新方案（RF+SHAP）：与问题3技术栈统一，实施成本低
4. 问题4创新方案（强化学习）：创新性最强但实施复杂度高

---

## 七、参考工具与库

| 模型类别 | Python库 | R语言包 | 备注 |
|----------|---------|--------|------|
| 约束优化 | CVXPY, Scipy.optimize | lpSolve, quadprog | 支持线性/二次规划 |
| 贝叶斯推断 | PyMC3, Stan, NumPyro | RStan, brms | MCMC采样 |
| 统计检验 | Scipy.stats, Statsmodels | stats, car | 假设检验 |
| 随机森林 | Scikit-learn | randomForest | 集成学习 |
| XGBoost | xgboost, lightgbm | xgboost | 梯度提升 |
| SHAP | shap | shapr | 可解释性 |
| 多目标优化 | Pymoo, DEAP | mco | 帕累托优化 |
| 强化学习 | Stable-baselines3, RLlib | - | RL算法 |

---

**文档生成时间**：2026年MCM竞赛

**适用对象**：2026年MCM C题参赛团队

**文档版本**：v1.0

**关联模块**：问题分析模块.md
